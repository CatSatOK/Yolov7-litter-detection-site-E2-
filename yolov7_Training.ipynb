{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6240c196-f8b8-46a1-a6f6-4b21dae08439",
   "metadata": {},
   "source": [
    "## Yolov7 training (done on Gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26262649-d196-4280-941a-9bea5d665aa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T08:20:53.168098Z",
     "iopub.status.busy": "2022-10-17T08:20:53.167034Z",
     "iopub.status.idle": "2022-10-17T08:21:31.341826Z",
     "shell.execute_reply": "2022-10-17T08:21:31.340847Z",
     "shell.execute_reply.started": "2022-10-17T08:20:53.168024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov7'...\n",
      "remote: Enumerating objects: 998, done.\u001b[K\n",
      "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
      "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
      "remote: Total 998 (delta 0), reused 0 (delta 0), pack-reused 994\u001b[K\n",
      "Receiving objects: 100% (998/998), 69.70 MiB | 2.40 MiB/s, done.\n",
      "Resolving deltas: 100% (493/493), done.\n",
      "Updating files: 100% (104/104), done.\n",
      "/notebooks/yolov7\n"
     ]
    }
   ],
   "source": [
    "# Download YOLOv7 repository and cd\n",
    "!git clone https://github.com/WongKinYiu/yolov7\n",
    "%cd yolov7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95aa73e-6e4e-484d-ba08-a916a04fb9dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#install requirements\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbcad15-d363-405e-9ecc-2cd0045cfeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch vision installs\n",
    "!pip install setuptools==59.5.0\n",
    "!pip install torchvision==0.11.3+cu111 -f https://download.pytorch.org/whl/cu111/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8683e939-f594-4b4f-844b-ceb5c8bbe23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading weights \n",
    "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "347c7701-ab4b-4363-86cd-7896e8c268b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/yolov7\n"
     ]
    }
   ],
   "source": [
    "#checking directory currently in\n",
    "%pwd\n",
    "#changing to correct directory\n",
    "cd yolov7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365f1dce-249c-482b-af04-673520bf8842",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T07:23:53.522962Z",
     "iopub.status.busy": "2022-10-20T07:23:53.522568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOR ðŸš€ v0.1-115-g072f76c torch 1.12.0+cu116 CUDA:0 (NVIDIA RTX A4000, 16117.3125MB)\n",
      "\n",
      "Namespace(weights='yolov7_training.pt', cfg='cfg/training/yolov7.yaml', data='data/taco.yaml', hyp='data/hyp.scratch.p5.yaml', epochs=150, batch_size=8, img_size=[512, 512], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='runs/train', entity=None, name='exp', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/exp62', total_batch_size=8)\n",
      "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n",
      "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 12                -1  1         0  models.common.MP                        []                            \n",
      " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
      " 25                -1  1         0  models.common.MP                        []                            \n",
      " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
      " 38                -1  1         0  models.common.MP                        []                            \n",
      " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
      " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
      " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
      " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 76                -1  1         0  models.common.MP                        []                            \n",
      " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
      " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 89                -1  1         0  models.common.MP                        []                            \n",
      " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
      " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
      " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
      "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
      "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
      "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
      "105   [102, 103, 104]  1    352402  models.yolo.IDetect                     [60, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
      "Model Summary: 415 layers, 37514802 parameters, 37514802 gradients\n",
      "\n",
      "Transferred 555/566 items from yolov7_training.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../datasets/train/labels.cache' images and labels... 1200 found\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '../datasets/val/labels.cache' images and labels... 150 found, 0 m\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 3.72, Best Possible Recall (BPR) = 0.9195. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mWARNING: Extremely small objects found. 169 of 3799 labels are < 3 pixels in size.\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 3799 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 0.9882 best possible recall, 3.58 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=512, metric_all=0.255/0.672-mean/best, past_thr=0.488-mean: 8,8,  21,21,  44,35,  54,70,  107,76,  108,160,  198,153,  148,333,  323,260\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7167: 100%|â–ˆ| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 0.9989 best possible recall, 4.29 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=512, metric_all=0.297/0.717-mean/best, past_thr=0.497-mean: 6,5,  10,10,  16,15,  31,28,  51,39,  58,68,  91,85,  128,157,  230,228\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 512 train, 512 test\n",
      "Using 8 dataloader workers\n",
      "Logging results to runs/train/exp62\n",
      "Starting training for 150 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     0/149     10.7G   0.07768   0.01325    0.0585    0.1494        44       512\n",
      "               Class      Images      Labels           P           R      mAP@.5/usr/local/lib/python3.9/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515     0.00415      0.0185     0.00298     0.00121\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     1/149     10.8G   0.05568   0.01373   0.05413    0.1235        42       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515       0.436      0.0888      0.0172     0.00903\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     2/149     10.8G   0.04902   0.01383   0.05246    0.1153       126       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515       0.663       0.049      0.0307      0.0179\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     3/149     10.8G   0.04688   0.01452   0.05124    0.1126        26       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515       0.584      0.0549      0.0313      0.0196\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     4/149     10.8G   0.05228   0.01286   0.05009    0.1152        90       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515       0.193       0.106      0.0183      0.0102\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     5/149     10.8G   0.05045    0.0129    0.0493    0.1127        75       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515         0.1       0.245      0.0215       0.013\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     6/149     10.8G   0.04719    0.0134   0.04898    0.1096        43       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515       0.486       0.115      0.0227      0.0138\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     7/149     10.8G    0.0429   0.01445   0.04883    0.1062        48       512"
     ]
    }
   ],
   "source": [
    "#Initial training call of custom model\n",
    "!python train.py --data data/taco.yaml --workers 8 --epochs 150 --batch-size 8 --cfg cfg/training/yolov7.yaml --img 512 --weights yolov7_training.pt --device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d43da472-380d-4f25-9b89-6572b4117be8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T14:19:25.177105Z",
     "iopub.status.busy": "2022-10-20T14:19:25.176147Z",
     "iopub.status.idle": "2022-10-20T15:54:16.042434Z",
     "shell.execute_reply": "2022-10-20T15:54:16.041587Z",
     "shell.execute_reply.started": "2022-10-20T14:19:25.177037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/yolov7\n",
      "Resuming training from ./runs/train/exp62/weights/last.pt\n",
      "YOLOR ðŸš€ v0.1-115-g072f76c torch 1.12.0+cu116 CUDA:0 (NVIDIA RTX A4000, 16117.3125MB)\n",
      "\n",
      "Namespace(weights='./runs/train/exp62/weights/last.pt', cfg='', data='data/taco.yaml', hyp='data/hyp.scratch.p5.yaml', epochs=150, batch_size=8, img_size=[512, 512], rect=False, resume=True, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='runs/train', entity=None, name='exp', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/exp62', total_batch_size=8)\n",
      "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n",
      "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 12                -1  1         0  models.common.MP                        []                            \n",
      " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
      " 25                -1  1         0  models.common.MP                        []                            \n",
      " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
      " 38                -1  1         0  models.common.MP                        []                            \n",
      " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
      " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
      " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
      " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 76                -1  1         0  models.common.MP                        []                            \n",
      " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
      " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 89                -1  1         0  models.common.MP                        []                            \n",
      " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
      " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
      " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
      "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
      "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
      "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
      "105   [102, 103, 104]  1    352402  models.yolo.IDetect                     [60, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
      "Model Summary: 415 layers, 37514802 parameters, 37514802 gradients\n",
      "\n",
      "Transferred 566/566 items from ./runs/train/exp62/weights/last.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../datasets/train/labels.cache' images and labels... 1200 found\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '../datasets/val/labels.cache' images and labels... 150 found, 0 m\u001b[0m\n",
      "Image sizes 512 train, 512 test\n",
      "Using 8 dataloader workers\n",
      "Logging results to runs/train/exp62\n",
      "Starting training for 150 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   123/149     10.9G   0.01962  0.009851   0.01225   0.04172        44       512\n",
      "               Class      Images      Labels           P           R      mAP@.5/usr/local/lib/python3.9/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515       0.943       0.583       0.681        0.61\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   124/149     10.9G   0.01917  0.009883   0.01192   0.04097        42       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515       0.907       0.586       0.685       0.604\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   125/149     10.9G   0.01934  0.009384   0.01193   0.04065       126       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515       0.893        0.59       0.686       0.604\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   126/149     10.9G   0.01985   0.01002   0.01202    0.0419        26       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515       0.884       0.598       0.692       0.608\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   127/149     10.9G    0.0192  0.009867   0.01158   0.04065        90       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515       0.897         0.6       0.689       0.602\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   128/149     10.9G   0.01901   0.01013   0.01237   0.04151        75       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515       0.898       0.598       0.699        0.62\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   129/149     10.9G   0.01946  0.009445   0.01176   0.04067        43       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515        0.94       0.575       0.689       0.608\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   130/149     10.9G    0.0189  0.009282   0.01222    0.0404        49       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515       0.831       0.632       0.687       0.606\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   131/149     10.9G   0.01939   0.01001   0.01185   0.04124        49       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515       0.919       0.599       0.694       0.616\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   132/149     10.9G   0.01872  0.009425   0.01135   0.03949        36       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515       0.931       0.598       0.714       0.636\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   133/149     10.9G   0.01901  0.009818   0.01146   0.04029        36       512\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   134/149     10.9G   0.01891  0.009627   0.01138   0.03993        39       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515       0.851       0.647         0.7       0.623\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   135/149     10.9G   0.01907   0.00956   0.01172   0.04035        19       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515       0.834       0.649       0.702       0.623\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   136/149     10.9G     0.019  0.009622   0.01139   0.04002        53       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515        0.92       0.597       0.693       0.619\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   137/149     10.9G    0.0189  0.009472    0.0109   0.03927        31       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515        0.83       0.651       0.695       0.618\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   138/149     10.9G     0.019   0.00925   0.01148   0.03973        42       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515       0.941       0.587       0.708       0.629\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   139/149     10.9G   0.01855  0.009149   0.01056   0.03827        26       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515       0.924       0.587        0.69       0.613\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   140/149     10.9G   0.01941  0.009498    0.0113    0.0402        51       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515       0.818       0.657       0.698       0.619\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   141/149     10.9G   0.01868  0.009498     0.011   0.03919        39       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515       0.852       0.643       0.692       0.615\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   142/149     10.9G   0.01875  0.009294   0.01088   0.03892        37       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515       0.899       0.632       0.699        0.62\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   143/149     10.9G   0.01869  0.009064   0.01106   0.03881        46       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515       0.905       0.628       0.695       0.618\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   144/149     10.9G   0.01841  0.009326   0.01069   0.03843        29       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515        0.88       0.633       0.709       0.632\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   145/149     10.9G   0.01863  0.009219   0.01025    0.0381        24       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515       0.903       0.636       0.712       0.635\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   146/149     10.9G   0.01902  0.008947   0.01027   0.03823        29       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515       0.894       0.644        0.71       0.634\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   147/149     10.9G   0.01885  0.009475   0.01049   0.03881        15       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515       0.909       0.641        0.72       0.644\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   148/149     10.9G    0.0184  0.009189   0.01013   0.03772        40       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515       0.886       0.628       0.698       0.625\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   149/149     10.9G   0.01847  0.009018   0.01003   0.03752        53       512\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515       0.868       0.635         0.7       0.624\n",
      "27 epochs completed in 1.547 hours.\n",
      "\n",
      "Optimizer stripped from runs/train/exp62/weights/last.pt, 75.4MB\n",
      "Optimizer stripped from runs/train/exp62/weights/best.pt, 75.4MB\n"
     ]
    }
   ],
   "source": [
    "#there were several cut outs so below is code used to restart training from last checkpoint (this is the final one)\n",
    "%cd yolov7\n",
    "!python train.py --resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4179197-2102-4708-a44e-1b8296f0c676",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T15:55:26.097080Z",
     "iopub.status.busy": "2022-10-20T15:55:26.096097Z",
     "iopub.status.idle": "2022-10-20T15:58:07.839983Z",
     "shell.execute_reply": "2022-10-20T15:58:07.839098Z",
     "shell.execute_reply.started": "2022-10-20T15:55:26.097045Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(weights=['runs/train/exp62/weights/best.pt'], source='../datasets/test/images', img_size=640, conf_thres=0.2, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n",
      "YOLOR ðŸš€ v0.1-115-g072f76c torch 1.12.0+cu116 CUDA:0 (NVIDIA RTX A4000, 16117.3125MB)\n",
      "\n",
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "IDetect.fuse\n",
      "Model Summary: 314 layers, 36800018 parameters, 6194944 gradients\n",
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n",
      "/usr/local/lib/python3.9/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "1 Paper bag, 1 Garbage bag, 1 Spread tub, 1 Disposable food container, Done. (7.8ms) Inference, (2.5ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_10_000026.jpg\n",
      "1 Plastic bottle cap, 1 Other carton, 1 Other plastic wrapper, 1 Unlabeled litter, 4 Cigarettes, Done. (7.4ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_10_000036.jpg\n",
      "1 Plastic film, Done. (11.1ms) Inference, (1.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_10_000056.jpg\n",
      "1 Plastic bottle cap, 1 Other plastic, 1 Plastic film, 1 Unlabeled litter, Done. (9.4ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_10_000066.jpg\n",
      "1 Other plastic, 1 Scrap metal, 1 Unlabeled litter, Done. (12.8ms) Inference, (1.3ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_10_000071.jpg\n",
      "1 Aluminium foil, 1 Broken glass, 1 Disposable plastic cup, 1 Unlabeled litter, 1 Cigarette, Done. (7.9ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_10_000096.jpg\n",
      "2 Corrugated cartons, Done. (7.8ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_11_000012.jpg\n",
      "1 Corrugated carton, 1 Styrofoam piece, Done. (8.5ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_11_000014.jpg\n",
      "1 Plastic film, Done. (7.9ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_11_000030.jpg\n",
      "1 Other carton, Done. (9.7ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_11_000031.jpg\n",
      "1 Styrofoam piece, Done. (7.6ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_11_000035.jpg\n",
      "1 Unlabeled litter, Done. (8.6ms) Inference, (1.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_11_000049.jpg\n",
      "1 Meal carton, 1 Other plastic wrapper, Done. (9.4ms) Inference, (1.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_11_000058.jpg\n",
      "1 Styrofoam piece, Done. (9.2ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_11_000077.jpg\n",
      "1 Meal carton, 2 Other plastic wrappers, 1 Crisp packet, Done. (9.4ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_11_000082.jpg\n",
      "2 Plastic films, Done. (8.9ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_11_000087.jpg\n",
      "1 Clear plastic bottle, 1 Other plastic, 1 Cigarette, Done. (9.3ms) Inference, (1.2ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_11_000090.jpg\n",
      "1 Drink can, 1 Wrapping paper, 1 Normal paper, 1 Plastic utensils, 1 Pop tab, 2 Unlabeled litters, 4 Cigarettes, Done. (9.4ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_11_000097.jpg\n",
      "1 Plastic bottle cap, Done. (8.8ms) Inference, (1.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_12_000002.jpg\n",
      "1 Meal carton, 2 Other plastic wrappers, Done. (8.6ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_12_000011.jpg\n",
      "1 Plastic bottle cap, 1 Other plastic, 1 Unlabeled litter, Done. (8.6ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_12_000014.jpg\n",
      "1 Paper cup, 1 Disposable plastic cup, 1 Crisp packet, 2 Pop tabs, Done. (8.6ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_12_000017.jpg\n",
      "1 Drink can, 4 Pop tabs, Done. (8.1ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_12_000018.jpg\n",
      "1 Plastic bottle cap, 1 Disposable plastic cup, 1 Plastic lid, 1 Disposable food container, 2 Pop tabs, 3 Cigarettes, Done. (8.3ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_12_000019.jpg\n",
      "1 Aerosol, 1 Other plastic, 1 Pop tab, 4 Cigarettes, Done. (8.2ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_12_000023.jpg\n",
      "1 Broken glass, 1 Meal carton, 2 Other plastic wrappers, 1 Plastic straw, Done. (8.1ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_12_000035.jpg\n",
      "1 Drink can, 1 Other carton, 1 Paper cup, 1 Single-use carrier bag, 1 Crisp packet, 1 Disposable food container, Done. (7.7ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_12_000066.jpg\n",
      "2 Drink cans, Done. (7.5ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_12_000077.jpg\n",
      "Done. (7.5ms) Inference, (0.2ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_13_000024.jpg\n",
      "1 Drink can, Done. (7.7ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_13_000037.jpg\n",
      "1 Battery, 1 Drink can, Done. (9.0ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_13_000055.jpg\n",
      "1 Plastic bottle cap, 1 Metal bottle cap, 1 Pop tab, Done. (8.6ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_13_000070.jpg\n",
      "1 Other plastic, Done. (9.2ms) Inference, (1.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_13_000075.jpg\n",
      "1 Plastic film, 2 Other plastic wrappers, 1 Unlabeled litter, 1 Cigarette, Done. (8.8ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_13_000083.jpg\n",
      "1 Other plastic wrapper, Done. (9.0ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_14_000000.jpg\n",
      "1 Other carton, 1 Pizza box, 1 Paper cup, 3 Plastic lids, 1 Wrapping paper, 2 Paper bags, 1 Spread tub, 1 Scrap metal, Done. (9.1ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_14_000022.jpg\n",
      "1 Plastic film, 1 Styrofoam piece, Done. (9.6ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_14_000034.jpg\n",
      "1 Plastic straw, 4 Cigarettes, Done. (9.7ms) Inference, (1.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_14_000041.jpg\n",
      "1 Other plastic bottle, 1 Plastic bottle cap, 1 Plastic straw, Done. (9.2ms) Inference, (1.4ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_14_000042.jpg\n",
      "1 Other plastic, 1 Unlabeled litter, Done. (8.8ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_14_000050.jpg\n",
      "1 Other carton, Done. (8.7ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_14_000059.jpg\n",
      "1 Normal paper, 2 Plastic films, Done. (9.4ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_14_000063.jpg\n",
      "1 Drink can, 1 Pop tab, Done. (9.2ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_14_000069.jpg\n",
      "1 Other plastic bottle, 1 Plastic bottle cap, Done. (9.0ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_14_000077.jpg\n",
      "1 Clear plastic bottle, 2 Drink cans, 1 Other plastic, 1 Plastic straw, Done. (9.8ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_14_000079.jpg\n",
      "1 Other plastic wrapper, Done. (8.9ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_14_000085.jpg\n",
      "1 Unlabeled litter, Done. (9.2ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_14_000093.jpg\n",
      "1 Glass bottle, Done. (9.4ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_15_000050.jpg\n",
      "1 Drink can, 1 Meal carton, 1 Paper cup, 2 Plastic films, 2 Other plastic wrappers, 1 Spread tub, Done. (10.1ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_15_000056.jpg\n",
      "1 Clear plastic bottle, 1 Plastic bottle cap, Done. (9.2ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_15_000057.jpg\n",
      "1 Plastic utensils, 1 Plastic straw, Done. (8.9ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_15_000061.jpg\n",
      "2 Clear plastic bottles, 1 Drink can, Done. (8.7ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_1_000019.jpg\n",
      "3 Drink cans, Done. (8.4ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_1_000024.jpg\n",
      "1 Egg carton, Done. (8.7ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_1_000066.JPG\n",
      "1 Drink can, Done. (9.4ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_1_000069.JPG\n",
      "1 Plastic straw, 6 Cigarettes, Done. (9.2ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_1_000076.JPG\n",
      "2 Broken glasss, 1 Plastic straw, 7 Cigarettes, Done. (9.0ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_1_000085.JPG\n",
      "1 Plastic bottle cap, 2 Plastic films, 1 Styrofoam piece, Done. (8.9ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_1_000105.JPG\n",
      "1 Drink can, 1 Other plastic wrapper, Done. (9.0ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_1_000110.JPG\n",
      "1 Crisp packet, Done. (9.1ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_1_000118.JPG\n",
      "1 Clear plastic bottle, 1 Plastic film, 2 Pop tabs, Done. (8.1ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_2_000019.JPG\n",
      "1 Clear plastic bottle, 1 Cigarette, Done. (8.0ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_2_000036.JPG\n",
      "1 Normal paper, 2 Unlabeled litters, 7 Cigarettes, Done. (8.9ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_2_000052.JPG\n",
      "1 Other carton, 1 Crisp packet, 1 Cigarette, Done. (9.7ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_2_000081.JPG\n",
      "1 Aluminium foil, 3 Glass bottles, 1 Drink can, 1 Plastic lid, 1 Plastic film, 1 Unlabeled litter, Done. (9.1ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_2_000082.JPG\n",
      "1 Plastic straw, 2 Cigarettes, Done. (9.8ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_2_000085.JPG\n",
      "1 Plastic film, Done. (8.9ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_2_000090.JPG\n",
      "1 Drink can, 1 Pop tab, Done. (9.1ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_3_IMG_4868.JPG\n",
      "1 Plastic film, 1 Unlabeled litter, 1 Cigarette, Done. (8.8ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_3_IMG_4881.JPG\n",
      "1 Plastic film, 1 Unlabeled litter, 1 Cigarette, Done. (7.7ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_3_IMG_4891.JPG\n",
      "1 Single-use carrier bag, 1 Unlabeled litter, 1 Cigarette, Done. (8.7ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_3_IMG_4898.JPG\n",
      "1 Corrugated carton, 1 Paper cup, 1 Plastic lid, 1 Paper bag, Done. (8.7ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_3_IMG_4939.JPG\n",
      "1 Disposable plastic cup, 1 Other plastic, 1 Plastic straw, Done. (10.3ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_3_IMG_4967.JPG\n",
      "1 Plastic bottle cap, 1 Pop tab, Done. (9.0ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_3_IMG_4971.JPG\n",
      "1 Drink can, Done. (8.6ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_3_IMG_4977.JPG\n",
      "1 Glass bottle, 1 Disposable plastic cup, 1 Other plastic, 1 Scrap metal, Done. (9.0ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_3_IMG_4994.JPG\n",
      "1 Drink can, Done. (9.0ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_3_IMG_5058.JPG\n",
      "3 Other plastics, 1 Plastic utensils, 1 Plastic straw, Done. (8.8ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_4_000010.JPG\n",
      "2 Other plastics, Done. (8.9ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_4_000022.JPG\n",
      "1 Other plastic, 1 Plastic straw, Done. (8.8ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_4_000036.JPG\n",
      "2 Rope & stringss, Done. (8.3ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_4_000046.JPG\n",
      "1 Food waste, 4 Other plastics, Done. (8.9ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_4_000054.JPG\n",
      "1 Plastic bottle cap, 1 Plastic film, Done. (9.3ms) Inference, (1.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_4_000055.JPG\n",
      "1 Plastic bottle cap, Done. (7.3ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_4_000062.JPG\n",
      "1 Meal carton, 1 Paper cup, 1 Other plastic, 1 Plastic utensils, Done. (8.2ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_4_000073.JPG\n",
      "Done. (8.7ms) Inference, (0.5ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_4_000074.JPG\n",
      "1 Plastic bottle cap, 1 Disposable plastic cup, 2 Other plastics, 1 Pop tab, Done. (9.0ms) Inference, (1.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_4_000096.JPG\n",
      "1 Clear plastic bottle, 1 Plastic bottle cap, Done. (9.2ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_5_000008.JPG\n",
      "1 Disposable plastic cup, 1 Plastic straw, Done. (9.5ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_5_000026.JPG\n",
      "1 Paper cup, 1 Plastic lid, 1 Rope & strings, Done. (10.0ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_5_000035.JPG\n",
      "1 Disposable plastic cup, 1 Plastic lid, 1 Other plastic, 1 Unlabeled litter, 1 Cigarette, Done. (8.8ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_5_000047.JPG\n",
      "1 Clear plastic bottle, 1 Plastic bottle cap, Done. (9.2ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_5_000052.JPG\n",
      "1 Disposable plastic cup, 1 Other plastic, 1 Styrofoam piece, 1 Unlabeled litter, Done. (9.7ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_5_000064.JPG\n",
      "1 Corrugated carton, Done. (8.8ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_5_000068.JPG\n",
      "1 Styrofoam piece, Done. (8.6ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_5_000089.JPG\n",
      "1 Disposable plastic cup, Done. (9.1ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_5_000096.JPG\n",
      "1 Other carton, Done. (9.3ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_5_000097.JPG\n",
      "1 Glass bottle, 1 Plastic film, Done. (8.8ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_5_000101.JPG\n",
      "1 Foam cup, 1 Plastic film, Done. (9.1ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_5_000118.JPG\n",
      "1 Plastic utensils, 1 Cigarette, Done. (8.9ms) Inference, (1.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_6_000003.JPG\n",
      "1 Drink can, 2 Crisp packets, Done. (9.0ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_6_000013.JPG\n",
      "1 Other plastic wrapper, Done. (9.3ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_6_000020.JPG\n",
      "1 Clear plastic bottle, Done. (8.8ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_6_000021.JPG\n",
      "2 Other plastics, 8 Unlabeled litters, 1 Cigarette, Done. (11.0ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_6_000031.JPG\n",
      "2 Clear plastic bottles, 2 Plastic bottle caps, Done. (8.2ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_6_000069.JPG\n",
      "1 Plastic lid, 1 Tupperware, 1 Disposable food container, Done. (8.5ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_6_000070.JPG\n",
      "2 Clear plastic bottles, 1 Other plastic wrapper, Done. (8.4ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_6_000087.JPG\n",
      "3 Clear plastic bottles, 1 Plastic bottle cap, 1 Other plastic wrapper, 1 Crisp packet, 1 Unlabeled litter, Done. (9.5ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_6_000097.JPG\n",
      "1 Corrugated carton, 1 Other plastic, 1 Other plastic wrapper, 1 Plastic straw, 1 Unlabeled litter, Done. (9.1ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_7_000004.JPG\n",
      "1 Drink can, 1 Paper bag, Done. (8.3ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_7_000011.JPG\n",
      "1 Plastic film, 1 Disposable food container, 2 Styrofoam pieces, Done. (8.4ms) Inference, (1.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_7_000019.JPG\n",
      "2 Other cartons, 1 Normal paper, 2 Plastic films, 1 Disposable food container, Done. (11.1ms) Inference, (1.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_7_000023.JPG\n",
      "1 Drink carton, 1 Pizza box, 1 Paper cup, 1 Plastic film, 3 Single-use carrier bags, 1 Plastic straw, Done. (9.5ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_7_000051.JPG\n",
      "1 Other plastic, 1 Normal paper, 1 Plastic film, 1 Single-use carrier bag, 1 Plastic straw, Done. (8.0ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_7_000054.JPG\n",
      "1 Plastic film, Done. (9.3ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_7_000055.JPG\n",
      "1 Other plastic wrapper, Done. (9.3ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_7_000060.JPG\n",
      "4 Plastic films, 1 Other plastic wrapper, Done. (8.3ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_7_000064.JPG\n",
      "1 Foam cup, 1 Plastic film, 1 Disposable food container, 1 Styrofoam piece, Done. (10.1ms) Inference, (1.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_7_000066.JPG\n",
      "1 Other plastic, 1 Plastic film, Done. (8.6ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_7_000067.JPG\n",
      "1 Plastic film, 1 Other plastic wrapper, Done. (9.1ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_7_000068.JPG\n",
      "1 Plastic film, Done. (7.6ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_7_000069.JPG\n",
      "1 Drink carton, 2 Unlabeled litters, Done. (8.7ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_7_000076.JPG\n",
      "1 Other plastic bottle, 1 Clear plastic bottle, 1 Plastic bottle cap, 6 Other cartons, 4 Drink cartons, 2 Magazine papers, 1 Plastic film, 8 Garbage bags, 4 Single-use carrier bags, 1 Crisp packet, 1 Pop tab, 1 Unlabeled litter, Done. (9.4ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_7_000078.JPG\n",
      "1 Other carton, 1 Drink carton, 1 Paper bag, 1 Garbage bag, Done. (9.5ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_7_000081.JPG\n",
      "1 Other plastic, Done. (8.8ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_7_000100.JPG\n",
      "1 Plastic film, Done. (10.2ms) Inference, (1.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_7_000121.JPG\n",
      "2 Plastic bottle caps, 1 Other plastic, 1 Other plastic wrapper, 1 Styrofoam piece, 1 Unlabeled litter, Done. (9.3ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_7_000129.JPG\n",
      "1 Single-use carrier bag, Done. (9.0ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_7_000133.JPG\n",
      "1 Disposable plastic cup, 1 Other plastic, 1 Tissues, 1 Unlabeled litter, Done. (9.1ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_8_000002.jpg\n",
      "1 Broken glass, 1 Drink can, 1 Pop tab, 2 Unlabeled litters, 1 Cigarette, Done. (7.8ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_8_000008.jpg\n",
      "1 Glass bottle, 1 Drink can, 1 Corrugated carton, 1 Plastic straw, Done. (9.3ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_8_000020.jpg\n",
      "1 Glass bottle, 1 Metal bottle cap, 1 Cigarette, Done. (8.7ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_8_000039.jpg\n",
      "1 Clear plastic bottle, 2 Glass bottles, 1 Plastic bottle cap, Done. (8.7ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_8_000040.jpg\n",
      "1 Food Can, 1 Paper cup, 1 Pop tab, 1 Plastic straw, Done. (8.8ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_8_000059.jpg\n",
      "1 Drink can, 1 Disposable plastic cup, 1 Plastic film, 1 Pop tab, Done. (10.0ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_8_000066.jpg\n",
      "1 Clear plastic bottle, 1 Glass bottle, 1 Unlabeled litter, Done. (7.4ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_8_000076.jpg\n",
      "1 Other plastic bottle, 1 Drink can, Done. (8.5ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_8_000083.jpg\n",
      "1 Clear plastic bottle, 1 Drink can, Done. (8.8ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_8_000088.jpg\n",
      "2 Cigarettes, Done. (8.4ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_8_000096.jpg\n",
      "2 Drink cans, 1 Unlabeled litter, Done. (9.2ms) Inference, (1.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_8_000097.jpg\n",
      "1 Other plastic, 1 Plastic utensils, 1 Plastic straw, 1 Styrofoam piece, Done. (8.4ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_9_000013.jpg\n",
      "1 Clear plastic bottle, 2 Other plastics, 1 Plastic film, Done. (10.8ms) Inference, (1.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_9_000014.jpg\n",
      "1 Plastic film, 1 Single-use carrier bag, 1 Unlabeled litter, Done. (8.8ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_9_000016.jpg\n",
      "2 Plastic films, Done. (8.4ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_9_000030.jpg\n",
      "1 Corrugated carton, 2 Pop tabs, 1 Plastic straw, 3 Unlabeled litters, Done. (8.0ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_9_000050.jpg\n",
      "1 Glass bottle, 1 Drink can, 1 Disposable plastic cup, 1 Plastic film, 1 Disposable food container, Done. (7.5ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_9_000073.jpg\n",
      "3 Clear plastic bottles, 4 Glass bottles, Done. (8.8ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_9_000074.jpg\n",
      "1 Glass bottle, Done. (7.9ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_9_000076.jpg\n",
      "2 Clear plastic bottles, 1 Plastic bottle cap, 1 Other carton, 1 Tissues, 1 Styrofoam piece, 4 Unlabeled litters, Done. (7.5ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_9_000084.jpg\n",
      "1 Other plastic wrapper, 1 Plastic straw, 1 Unlabeled litter, Done. (7.8ms) Inference, (0.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp5/batch_9_000091.jpg\n",
      "Done. (145.444s)\n"
     ]
    }
   ],
   "source": [
    "#running detect\n",
    "!python detect.py --weights runs/train/exp62/weights/best.pt --conf 0.2 --source ../datasets/test/images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use below code to plot the inferences on test images to visually assess effectivness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3710f2c-a50d-4964-87af-7a299ee3a31a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T16:01:08.670831Z",
     "iopub.status.busy": "2022-10-20T16:01:08.670304Z",
     "iopub.status.idle": "2022-10-20T16:01:09.434491Z",
     "shell.execute_reply": "2022-10-20T16:01:09.433906Z",
     "shell.execute_reply.started": "2022-10-20T16:01:08.670807Z"
    }
   },
   "outputs": [],
   "source": [
    "#plotting inference on some test images\n",
    "\n",
    "import glob\n",
    "from IPython.display import Image, display\n",
    "\n",
    "i = 0\n",
    "limit = 10 # max images to print\n",
    "for imageName in glob.glob('runs/detect/exp5/*.jpg'): \n",
    "    if i < limit:\n",
    "      display(Image(filename=imageName))\n",
    "      print(\"\\n\")\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30635ea7-4f4d-4387-b59f-ac0b216f30a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T13:33:57.402586Z",
     "iopub.status.busy": "2023-04-19T13:33:57.402237Z",
     "iopub.status.idle": "2023-04-19T13:35:02.119475Z",
     "shell.execute_reply": "2023-04-19T13:35:02.117643Z",
     "shell.execute_reply.started": "2023-04-19T13:33:57.402558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(weights=['runs/train/exp63/weights/best.pt'], data='data/taco.yaml', batch_size=16, img_size=1280, conf_thres=0.001, iou_thres=0.65, task='val', device='0', single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project='runs/test', name='exp', exist_ok=False, no_trace=False, v5_metric=False)\n",
      "YOLOR ðŸš€ v0.1-115-g072f76c torch 1.12.0+cu116 CUDA:0 (Quadro P5000, 16278.625MB)\n",
      "\n",
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "IDetect.fuse\n",
      "Model Summary: 314 layers, 36800018 parameters, 6194944 gradients\n",
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n",
      "/usr/local/lib/python3.9/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '../datasets/val/labels.cache' images and labels... 150 found, 0 m\u001b[0m\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515       0.602       0.532       0.575       0.499\n",
      "Speed: 79.4/2.5/81.9 ms inference/NMS/total per 1280x1280 image at batch-size 16\n",
      "Results saved to runs/test/exp\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "!python test.py --data data/taco.yaml --img 1280--batch 16 --conf 0.001 --iou 0.65 --device 0 --weights runs/train/exp63/weights/best.pt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27bca514-2c39-4744-94fb-1c6cf890d793",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T13:57:07.921963Z",
     "iopub.status.busy": "2023-04-19T13:57:07.921568Z",
     "iopub.status.idle": "2023-04-19T13:58:02.095981Z",
     "shell.execute_reply": "2023-04-19T13:58:02.095071Z",
     "shell.execute_reply.started": "2023-04-19T13:57:07.921934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(weights=['runs/train/exp63/weights/best.pt'], data='data/taco.yaml', batch_size=32, img_size=640, conf_thres=0.001, iou_thres=0.65, task='val', device='0', single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project='runs/test', name='exp', exist_ok=False, no_trace=False, v5_metric=False)\n",
      "YOLOR ðŸš€ v0.1-115-g072f76c torch 1.12.0+cu116 CUDA:0 (Quadro P5000, 16278.625MB)\n",
      "\n",
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "IDetect.fuse\n",
      "Model Summary: 314 layers, 36800018 parameters, 6194944 gradients\n",
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n",
      "/usr/local/lib/python3.9/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '../datasets/val/labels.cache' images and labels... 150 found, 0 m\u001b[0m\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         149         515       0.857       0.695       0.741       0.671\n",
      "Speed: 23.4/3.4/26.8 ms inference/NMS/total per 640x640 image at batch-size 32\n",
      "Results saved to runs/test/exp2\n"
     ]
    }
   ],
   "source": [
    "#trying with different paramenters\n",
    "!python test.py --data data/taco.yaml --img 640 --batch 32 --conf 0.001 --iou 0.65 --device 0 --weights runs/train/exp63/weights/best.pt "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
